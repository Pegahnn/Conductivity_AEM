{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSspCVyID1x_",
        "outputId": "347b548b-c08c-4be2-d32a-f83b21d97494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio torch-geometric optuna dgllife pandas scikit-learn tensorboard rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzJ8xNYPGWaR",
        "outputId": "20060a4a-d442-409a-9fc8-917994a49cdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from dgllife) (1.16.3)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.12/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from dgllife) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt->dgllife) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from hyperopt->dgllife) (3.1.2)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt->dgllife) (0.10.9.9)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: rdkit, colorlog, torch-geometric, optuna, dgllife\n",
            "Successfully installed colorlog-6.10.1 dgllife-0.3.2 optuna-4.6.0 rdkit-2025.9.3 torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then update path\n",
        "CSV_PATH = \"/content/drive/MyDrive/Pegah_works/modified_data_final.csv\""
      ],
      "metadata": {
        "id": "B12gvtw0FZY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Go to your working directory\n",
        "%cd /content/drive/MyDrive/Pegah_works"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXKP5a9rHKHI",
        "outputId": "58ded0df-a1f6-4170-c8fb-334c0592af92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pegah_works\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# Graph Joint Autoencoder + Regressor + Ensemble + HPO (PyG)\n",
        "# ===========================================================\n",
        "# - PyTorch 2.6 / PyG 2.5 compatible\n",
        "# - R²-first hyperparameter search with tie-break on MAE\n",
        "# - Denoising AE pretrain (node feature recon: BCE on binary, MSE on cont.)\n",
        "# - Joint fine-tune with supervised + light reconstruction\n",
        "# - CosineAnnealingWarmRestarts + SWA, ensemble across diverse seeds\n",
        "# - Saves HPO log and final artifacts (+ target transformer for inference)\n",
        "# ===========================================================\n",
        "\n",
        "import os, json, random, numpy as np, pandas as pd, torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import rdchem\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool, BatchNorm\n",
        "\n",
        "import joblib\n",
        "\n",
        "# ---------------------------\n",
        "# Reproducibility / Device\n",
        "# ---------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------------\n",
        "# Paths\n",
        "# ---------------------------\n",
        "CSV_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/modified_data_final_2.csv\"\n",
        "HPO_LOG_PATH = \"graph_hpo_log.json\"\n",
        "ARTIFACT_PATH = \"option4b_graph_joint_ae_regressor_ensemble.pt\"\n",
        "PT_PATH = \"target_transform.joblib\"\n",
        "\n",
        "# ---------------------------\n",
        "# Base Config (can be overridden by HPO)\n",
        "# ---------------------------\n",
        "BASE_CFG = dict(\n",
        "    # Featurization\n",
        "    atom_nums=[1,6,7,8,9,15,16,17,35,53],\n",
        "    max_degree=5,\n",
        "    charges=[-2,-1,0,1,2],\n",
        "    hybs=[rdchem.HybridizationType.SP, rdchem.HybridizationType.SP2, rdchem.HybridizationType.SP3,\n",
        "          rdchem.HybridizationType.SP3D, rdchem.HybridizationType.SP3D2],\n",
        "    bond_types=[rdchem.BondType.SINGLE, rdchem.BondType.DOUBLE, rdchem.BondType.TRIPLE, rdchem.BondType.AROMATIC],\n",
        "    force_reprocess=False,\n",
        "\n",
        "    # Encoder (GNN)\n",
        "    enc_hidden=128,\n",
        "    enc_layers=3,\n",
        "    enc_dropout=0.10,\n",
        "\n",
        "    # AE pretrain\n",
        "    ae_lr=1e-3,\n",
        "    ae_weight_decay=1e-5,\n",
        "    ae_epochs=150,\n",
        "    ae_batch_size=64,\n",
        "    ae_feat_drop=0.10,\n",
        "\n",
        "    # Regressor (Dense + SE)\n",
        "    growth=256,\n",
        "    n_blocks=4,\n",
        "    dropout=0.28,\n",
        "    head_hidden=384,\n",
        "\n",
        "    # Joint training\n",
        "    lr=1.05e-3,\n",
        "    weight_decay=9e-4,\n",
        "    batch_size=32,\n",
        "    epochs=600,\n",
        "    T0=70,\n",
        "    Tmult=1,\n",
        "    swa_ratio=0.33,\n",
        "\n",
        "    # Loss mix\n",
        "    alpha=0.65,\n",
        "    sup_weight=0.90,\n",
        "    recon_weight=0.10,\n",
        "\n",
        "    # Data split / ensemble\n",
        "    val_split=0.10,\n",
        "    ensemble_size=10\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Atom / Bond Features\n",
        "# ---------------------------\n",
        "def atom_features(atom, cfg):\n",
        "    nums, hybs, charges, max_deg = cfg[\"atom_nums\"], cfg[\"hybs\"], cfg[\"charges\"], cfg[\"max_degree\"]\n",
        "    f_num = [1.0 if atom.GetAtomicNum()==z else 0.0 for z in nums] + [0.0]\n",
        "    if sum(f_num[:-1]) == 0: f_num[-1] = 1.0\n",
        "    d = atom.GetTotalDegree()\n",
        "    f_deg = [1.0 if d==k else 0.0 for k in range(max_deg+1)] + [1.0 if d>max_deg else 0.0]\n",
        "    ch = atom.GetFormalCharge()\n",
        "    f_ch = [1.0 if ch==c else 0.0 for c in charges] + [1.0 if ch not in charges else 0.0]\n",
        "    hyb = atom.GetHybridization()\n",
        "    f_hy = [1.0 if hyb==h else 0.0 for h in hybs] + [1.0 if hyb not in hybs else 0.0]\n",
        "    f_bin_misc = [float(atom.GetIsAromatic()), float(atom.IsInRing())]\n",
        "    f_cont = [float(atom.GetTotalNumHs(includeNeighbors=True)), float(atom.GetImplicitValence())]\n",
        "    return np.array(f_num + f_deg + f_ch + f_hy + f_bin_misc + f_cont, dtype=np.float32)\n",
        "\n",
        "def bond_features(bond, cfg):\n",
        "    btypes = cfg[\"bond_types\"]\n",
        "    f_bt = [1.0 if bond.GetBondType()==t else 0.0 for t in btypes] + [0.0]\n",
        "    if sum(f_bt[:-1]) == 0: f_bt[-1] = 1.0\n",
        "    f_misc = [float(bond.GetIsConjugated()), float(bond.IsInRing())]\n",
        "    return np.array(f_bt + f_misc, dtype=np.float32)\n",
        "\n",
        "def get_atom_feature_dims(cfg):\n",
        "    bin_dim = (len(cfg[\"atom_nums\"])+1) + (cfg[\"max_degree\"]+1+1) + (len(cfg[\"charges\"])+1) + (len(cfg[\"hybs\"])+1) + 2\n",
        "    cont_dim = 2\n",
        "    return bin_dim, cont_dim\n",
        "\n",
        "def smiles_to_pyg(smiles, y, cfg):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None: return None\n",
        "    Chem.Kekulize(mol, clearAromaticFlags=False)\n",
        "    x = torch.tensor(np.vstack([atom_features(a, cfg) for a in mol.GetAtoms()]), dtype=torch.float32)\n",
        "\n",
        "    ei_src, ei_dst, eattr = [], [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        bf = bond_features(b, cfg)\n",
        "        ei_src += [i, j]; ei_dst += [j, i]\n",
        "        eattr.append(bf); eattr.append(bf)\n",
        "\n",
        "    if len(ei_src) == 0:\n",
        "        edge_index = torch.empty((2,0), dtype=torch.long)\n",
        "        edge_attr  = torch.empty((0, len(cfg[\"bond_types\"]) + 2 + 1), dtype=torch.float32)\n",
        "    else:\n",
        "        edge_index = torch.tensor([ei_src, ei_dst], dtype=torch.long)\n",
        "        edge_attr  = torch.tensor(np.vstack(eattr), dtype=torch.float32)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr,\n",
        "                y=torch.tensor([float(y)], dtype=torch.float32))\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class GraphDataset(InMemoryDataset):\n",
        "    def __init__(self, csv_path, cfg, force_reprocess=False):\n",
        "        self.csv_path = csv_path\n",
        "        self.cfg = cfg\n",
        "        self._procdir = \".proc_graph_pt26\"\n",
        "        os.makedirs(self._procdir, exist_ok=True)\n",
        "        super().__init__(self._procdir)\n",
        "        fname = self.processed_paths[0]\n",
        "        if force_reprocess or (not os.path.exists(fname)):\n",
        "            self.process()\n",
        "        try:\n",
        "            self.data, self.slices = torch.load(fname, weights_only=False)\n",
        "        except Exception:\n",
        "            self.process()\n",
        "            self.data, self.slices = torch.load(fname, weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        base = os.path.splitext(os.path.basename(self.csv_path))[0]\n",
        "        return [f\"{base}_graphs.pt\"]\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        smiles = df.iloc[:, 0].astype(str).tolist()\n",
        "        num_feats = df.iloc[:, 1:-1].astype(float).values\n",
        "        targets = df.iloc[:, -1].astype(float).tolist()\n",
        "\n",
        "        data_list = []\n",
        "        for s, nf, t in zip(smiles, num_feats, targets):\n",
        "            d = smiles_to_pyg(s, t, self.cfg)\n",
        "            if d is not None:\n",
        "                # store as (4,) per graph; batching may flatten -> we reshape in forward robustly\n",
        "                d.num_feats = torch.tensor(nf, dtype=torch.float32)\n",
        "                data_list.append(d)\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "# ---------------------------\n",
        "# Target Transform (list-safe, warning-free)\n",
        "# ---------------------------\n",
        "def _iter_y(dataset):\n",
        "    if isinstance(dataset, list):\n",
        "        return np.array([float(d.y.item()) for d in dataset], dtype=np.float32).reshape(-1, 1)\n",
        "    else:\n",
        "        y = torch.stack([dataset.get(i).y for i in range(len(dataset))]).cpu().numpy().reshape(-1, 1)\n",
        "        return y.astype(np.float32)\n",
        "\n",
        "def fit_target_transform(dataset):\n",
        "    y = _iter_y(dataset)\n",
        "    pt = PowerTransformer(method=\"yeo-johnson\", standardize=True)\n",
        "    y_t = pt.fit_transform(y).astype(np.float32)\n",
        "\n",
        "    if isinstance(dataset, list):\n",
        "        for i in range(len(dataset)):\n",
        "            dataset[i].y = torch.tensor([y_t[i, 0]], dtype=torch.float32)\n",
        "    else:\n",
        "        # write to underlying storage and clear cached list\n",
        "        dataset._data.y = torch.tensor(y_t, dtype=torch.float32).view(-1, 1)\n",
        "        dataset._data_list = None\n",
        "    return pt\n",
        "\n",
        "def inverse_target(pt, y_np):\n",
        "    y_np = np.asarray(y_np, dtype=np.float64)\n",
        "    y_np = np.nan_to_num(y_np, nan=0.0, posinf=10.0, neginf=-10.0)\n",
        "    y_np = np.clip(y_np, -10, 10)\n",
        "    try:\n",
        "        inv = pt.inverse_transform(y_np.reshape(-1,1)).ravel()\n",
        "    except Exception:\n",
        "        inv = y_np\n",
        "    inv = np.nan_to_num(inv, nan=0.0, posinf=np.finfo(np.float32).max/2, neginf=np.finfo(np.float32).min/2)\n",
        "    return inv.astype(np.float32)\n",
        "\n",
        "# ---------------------------\n",
        "# Model Definitions\n",
        "# ---------------------------\n",
        "class GNNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, layers, dropout, edge_dim):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        last = in_dim\n",
        "        for _ in range(layers):\n",
        "            mlp = nn.Sequential(nn.Linear(last, hidden), nn.ReLU(), nn.Linear(hidden, hidden))\n",
        "            self.convs.append(GINEConv(mlp, edge_dim=edge_dim))\n",
        "            self.bns.append(BatchNorm(hidden))\n",
        "            last = hidden\n",
        "        self.dropout = dropout\n",
        "        self.out_dim = hidden\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        for conv, bn in zip(self.convs, self.bns):\n",
        "            x = conv(x, edge_index, edge_attr)\n",
        "            x = bn(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "class NodeFeatDecoder(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_dim, out_dim)\n",
        "        )\n",
        "    def forward(self, h_nodes):\n",
        "        return self.net(h_nodes)\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, dim, reduction=8):\n",
        "        super().__init__()\n",
        "        hidden = max(4, dim // reduction)\n",
        "        self.fc1 = nn.Linear(dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, dim)\n",
        "    def forward(self, x):\n",
        "        w = torch.sigmoid(self.fc2(F.relu(self.fc1(x))))\n",
        "        return x * w\n",
        "\n",
        "class DenseSERegressor(nn.Module):\n",
        "    def __init__(self, in_dim, growth, n_blocks, dropout, head_hidden):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Sequential(\n",
        "            nn.Linear(in_dim, growth),\n",
        "            nn.BatchNorm1d(growth),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        ))\n",
        "        for _ in range(n_blocks - 1):\n",
        "            layers.append(nn.Sequential(\n",
        "                nn.Linear(growth, growth),\n",
        "                nn.BatchNorm1d(growth),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "        self.se = SEBlock(growth, reduction=8)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(growth, head_hidden),\n",
        "            nn.BatchNorm1d(head_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(head_hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.blocks(z)\n",
        "        h = self.se(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class JointGraphAER(nn.Module):\n",
        "    def __init__(self, node_in, edge_in, cfg, num_extra_feats=4):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(node_in, cfg[\"enc_hidden\"], cfg[\"enc_layers\"], cfg[\"enc_dropout\"], edge_in)\n",
        "        self.decoder = NodeFeatDecoder(cfg[\"enc_hidden\"], node_in)\n",
        "        self.num_extra_feats = num_extra_feats\n",
        "        self.regressor = DenseSERegressor(\n",
        "            in_dim=cfg[\"enc_hidden\"] + num_extra_feats,\n",
        "            growth=cfg[\"growth\"],\n",
        "            n_blocks=cfg[\"n_blocks\"],\n",
        "            dropout=cfg[\"dropout\"],\n",
        "            head_hidden=cfg[\"head_hidden\"]\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        h_nodes = self.encoder(x, edge_index, edge_attr)\n",
        "        z_graph = global_mean_pool(h_nodes, batch)  # (B, enc_hidden)\n",
        "\n",
        "        # -------- FIX: robust batching of num_feats --------\n",
        "        if self.num_extra_feats > 0:\n",
        "            if hasattr(data, \"num_feats\") and data.num_feats is not None:\n",
        "                nf = data.num_feats.to(z_graph.device)\n",
        "\n",
        "                # PyG may flatten graph-level attributes into 1D (B*F,)\n",
        "                if nf.dim() == 1:\n",
        "                    nf = nf.view(z_graph.size(0), -1)\n",
        "\n",
        "                # If it came as (B, F) but F mismatched, clamp/pad\n",
        "                if nf.size(0) != z_graph.size(0):\n",
        "                    # last resort: try reshape using B\n",
        "                    nf = nf.reshape(z_graph.size(0), -1)\n",
        "\n",
        "                if nf.size(1) > self.num_extra_feats:\n",
        "                    nf = nf[:, :self.num_extra_feats]\n",
        "                elif nf.size(1) < self.num_extra_feats:\n",
        "                    pad = torch.zeros(z_graph.size(0), self.num_extra_feats - nf.size(1), device=z_graph.device)\n",
        "                    nf = torch.cat([nf, pad], dim=1)\n",
        "\n",
        "                z_graph = torch.cat([z_graph, nf], dim=1)\n",
        "            else:\n",
        "                pad = torch.zeros(z_graph.size(0), self.num_extra_feats, device=z_graph.device)\n",
        "                z_graph = torch.cat([z_graph, pad], dim=1)\n",
        "\n",
        "        y_hat = self.regressor(z_graph)\n",
        "        x_logits = self.decoder(h_nodes)\n",
        "        return y_hat, x_logits, h_nodes, z_graph\n",
        "\n",
        "# ---------------------------\n",
        "# Data Loaders (list-safe)\n",
        "# ---------------------------\n",
        "def make_split_loaders(dataset, cfg, seed):\n",
        "    n = len(dataset)\n",
        "    n_val = max(1, int(cfg[\"val_split\"] * n))\n",
        "    n_tr = max(1, n - n_val)\n",
        "\n",
        "    gen = torch.Generator().manual_seed(seed)\n",
        "\n",
        "    if isinstance(dataset, list):\n",
        "        idx = torch.randperm(n, generator=gen).tolist()\n",
        "        tr_idx = idx[:n_tr]\n",
        "        va_idx = idx[n_tr:n_tr+n_val]\n",
        "        tr_ds = [dataset[i] for i in tr_idx]\n",
        "        va_ds = [dataset[i] for i in va_idx]\n",
        "    else:\n",
        "        tr_ds, va_ds = random_split(dataset, [n_tr, n_val], generator=gen)\n",
        "\n",
        "    bs_tr = min(cfg[\"batch_size\"], len(tr_ds)); bs_tr = bs_tr if bs_tr > 0 else 1\n",
        "    bs_va = min(cfg[\"batch_size\"], len(va_ds)); bs_va = bs_va if bs_va > 0 else 1\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=bs_tr, shuffle=True, drop_last=False)\n",
        "    va_loader = DataLoader(va_ds, batch_size=bs_va, shuffle=False, drop_last=False)\n",
        "    return tr_loader, va_loader\n",
        "\n",
        "def eval_ensemble(models, loader, pt):\n",
        "    yhat_all, ytrue_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            preds = []\n",
        "            for m in models:\n",
        "                y_hat, _, _, _ = m(data)\n",
        "                preds.append(y_hat.squeeze(1).cpu().numpy())\n",
        "            p_mean = np.mean(preds, axis=0)\n",
        "            yhat_all.append(p_mean)\n",
        "            ytrue_all.append(data.y.cpu().numpy().ravel())\n",
        "    y_pred = np.concatenate(yhat_all)\n",
        "    y_true = np.concatenate(ytrue_all)\n",
        "    y_pred_inv = inverse_target(pt, y_pred)\n",
        "    y_true_inv = inverse_target(pt, y_true)\n",
        "    mae = mean_absolute_error(y_true_inv, y_pred_inv)\n",
        "    mse = mean_squared_error(y_true_inv, y_pred_inv)\n",
        "    rmse = float(np.sqrt(mse))\n",
        "    r2 = r2_score(y_true_inv, y_pred_inv)\n",
        "    return dict(mae=mae, mse=mse, rmse=rmse, r2=r2)\n",
        "\n",
        "# ---------------------------\n",
        "# Training Loops\n",
        "# ---------------------------\n",
        "def pretrain_encoder(dataset, cfg, bin_dim, cont_dim, epochs_override=None, seed=SEED):\n",
        "    torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "\n",
        "    sample = dataset[0] if isinstance(dataset, list) else dataset.get(0)\n",
        "    node_in = sample.x.shape[1]\n",
        "    edge_in = sample.edge_attr.shape[1] if sample.edge_attr is not None and sample.edge_attr.numel() > 0 else 0\n",
        "\n",
        "    model = JointGraphAER(node_in, edge_in, cfg, num_extra_feats=0).to(device)\n",
        "\n",
        "    params = list(model.encoder.parameters()) + list(model.decoder.parameters())\n",
        "    opt = torch.optim.AdamW(params, lr=cfg[\"ae_lr\"], weight_decay=cfg[\"ae_weight_decay\"])\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=40, T_mult=1)\n",
        "    bce = nn.BCEWithLogitsLoss(); mse = nn.MSELoss()\n",
        "\n",
        "    tr_loader, _ = make_split_loaders(dataset, cfg, seed)\n",
        "    E = epochs_override if epochs_override is not None else cfg[\"ae_epochs\"]\n",
        "\n",
        "    for epoch in range(E):\n",
        "        model.train()\n",
        "        for data in tr_loader:\n",
        "            data = data.to(device)\n",
        "            opt.zero_grad()\n",
        "            _, x_logits, _, _ = model(data)\n",
        "            x_bin = data.x[:, :bin_dim]; x_cont = data.x[:, bin_dim:bin_dim+cont_dim]\n",
        "            xl_bin = x_logits[:, :bin_dim]; xl_cont = x_logits[:, bin_dim:bin_dim+cont_dim]\n",
        "            loss = bce(xl_bin, x_bin) + mse(xl_cont, x_cont)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "        sched.step(epoch)\n",
        "\n",
        "    return {\"encoder\": model.encoder.state_dict(),\n",
        "            \"decoder\": model.decoder.state_dict(),\n",
        "            \"node_in\": node_in,\n",
        "            \"edge_in\": edge_in}\n",
        "\n",
        "def train_single_joint(dataset, pt, ae_init, cfg, seed_offset, bin_dim, cont_dim, epochs_override=None):\n",
        "    seed = SEED + seed_offset\n",
        "    torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "\n",
        "    tr_loader, va_loader = make_split_loaders(dataset, cfg, seed)\n",
        "    model = JointGraphAER(ae_init[\"node_in\"], ae_init[\"edge_in\"], cfg, num_extra_feats=4).to(device)\n",
        "    model.encoder.load_state_dict(ae_init[\"encoder\"])\n",
        "    model.decoder.load_state_dict(ae_init[\"decoder\"])\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cfg[\"T0\"], T_mult=cfg[\"Tmult\"])\n",
        "\n",
        "    E = epochs_override if epochs_override is not None else cfg[\"epochs\"]\n",
        "    swa_start_epoch = int((1.0 - cfg[\"swa_ratio\"]) * E)\n",
        "    swa_model = AveragedModel(model)\n",
        "    swa_scheduler = SWALR(optimizer, swa_lr=cfg[\"lr\"] * 0.1)\n",
        "\n",
        "    sl1 = nn.SmoothL1Loss(); mse = nn.MSELoss(); bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(E):\n",
        "        model.train()\n",
        "\n",
        "        if epoch == 0:\n",
        "            sample_data = next(iter(tr_loader)).to(device)\n",
        "            with torch.no_grad():\n",
        "                _, _, _, z_graph_dbg = model(sample_data)\n",
        "            print(f\"[DEBUG] Epoch {epoch} — z_graph: {z_graph_dbg.shape}, \"\n",
        "                  f\"Regressor in_features: {model.regressor.blocks[0][0].in_features}\")\n",
        "\n",
        "        for data in tr_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat, x_logits, _, _ = model(data)\n",
        "\n",
        "            sup = cfg[\"alpha\"] * sl1(y_hat, data.y.unsqueeze(1)) + (1.0 - cfg[\"alpha\"]) * mse(y_hat, data.y.unsqueeze(1))\n",
        "\n",
        "            x_bin = data.x[:, :bin_dim]; x_cont = data.x[:, bin_dim:bin_dim+cont_dim]\n",
        "            xl_bin = x_logits[:, :bin_dim]; xl_cont = x_logits[:, bin_dim:bin_dim+cont_dim]\n",
        "            recon = bce(xl_bin, x_bin) + mse(xl_cont, x_cont)\n",
        "\n",
        "            loss = cfg[\"sup_weight\"] * sup + cfg[\"recon_weight\"] * recon\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch < swa_start_epoch:\n",
        "            scheduler.step(epoch)\n",
        "        else:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_scheduler.step()\n",
        "\n",
        "    update_bn(tr_loader, swa_model, device=device)\n",
        "    return swa_model, va_loader\n",
        "\n",
        "# ---------------------------\n",
        "# CV Pipeline (list-safe)\n",
        "# ---------------------------\n",
        "def run_cv_pipeline(cfg, n_splits=5):\n",
        "    print(f\"\\n=== {n_splits}-Fold Cross-Validation ===\")\n",
        "    ds = GraphDataset(CSV_PATH, cfg, force_reprocess=cfg.get(\"force_reprocess\", False))\n",
        "    bin_dim, cont_dim = get_atom_feature_dims(cfg)\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    indices = np.arange(len(ds))\n",
        "    metrics_list = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(indices), 1):\n",
        "        print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "        tr_list = [ds[int(i)] for i in train_idx]\n",
        "        va_list = [ds[int(i)] for i in val_idx]\n",
        "\n",
        "        pt_fold = fit_target_transform(tr_list)  # fit ONLY on training fold\n",
        "        # apply same transform to val fold\n",
        "        y_val = np.array([float(d.y.item()) for d in va_list], dtype=np.float32).reshape(-1, 1)\n",
        "        y_val_t = pt_fold.transform(y_val).astype(np.float32)\n",
        "        for i in range(len(va_list)):\n",
        "            va_list[i].y = torch.tensor([y_val_t[i, 0]], dtype=torch.float32)\n",
        "\n",
        "        ae_init = pretrain_encoder(tr_list, cfg, bin_dim, cont_dim, epochs_override=cfg[\"ae_epochs\"], seed=SEED+fold)\n",
        "        model, _ = train_single_joint(tr_list, pt_fold, ae_init, cfg, seed_offset=fold*11,\n",
        "                                      bin_dim=bin_dim, cont_dim=cont_dim, epochs_override=cfg[\"epochs\"])\n",
        "\n",
        "        va_loader = DataLoader(va_list, batch_size=min(cfg[\"batch_size\"], len(va_list)), shuffle=False)\n",
        "        metrics = eval_ensemble([model], va_loader, pt_fold)\n",
        "        metrics_list.append(metrics)\n",
        "\n",
        "        print(f\"[Fold {fold}] R²={metrics['r2']:.4f}  MAE={metrics['mae']:.4f}  RMSE={metrics['rmse']:.4f}\")\n",
        "\n",
        "    r2s = [m[\"r2\"] for m in metrics_list]\n",
        "    maes = [m[\"mae\"] for m in metrics_list]\n",
        "    rmses = [m[\"rmse\"] for m in metrics_list]\n",
        "\n",
        "    summary = {\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"MAE_mean\": float(np.mean(maes)),\n",
        "        \"MAE_std\": float(np.std(maes)),\n",
        "        \"RMSE_mean\": float(np.mean(rmses)),\n",
        "        \"RMSE_std\": float(np.std(rmses))\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== CV Summary ===\")\n",
        "    print(f\"R²:   {summary['R2_mean']:.4f} ± {summary['R2_std']:.4f}\")\n",
        "    print(f\"MAE:  {summary['MAE_mean']:.4f} ± {summary['MAE_std']:.4f}\")\n",
        "    print(f\"RMSE: {summary['RMSE_mean']:.4f} ± {summary['RMSE_std']:.4f}\")\n",
        "    return summary, metrics_list\n",
        "\n",
        "# ---------------------------\n",
        "# HPO: R²-first Random Search\n",
        "# ---------------------------\n",
        "def sample_cfg(base):\n",
        "    cfg = dict(base)\n",
        "\n",
        "    cfg[\"enc_hidden\"]   = random.choice([128, 160, 192, 224, 256])\n",
        "    cfg[\"enc_layers\"]   = random.choice([3, 4, 5])\n",
        "    cfg[\"enc_dropout\"]  = random.choice([0.05, 0.08, 0.10, 0.12, 0.15])\n",
        "\n",
        "    cfg[\"growth\"]       = random.choice([192, 224, 256, 320])\n",
        "    cfg[\"n_blocks\"]     = random.choice([3, 4, 5])\n",
        "    cfg[\"dropout\"]      = random.choice([0.10, 0.15, 0.20, 0.25])\n",
        "    cfg[\"head_hidden\"]  = random.choice([256, 320, 384, 512])\n",
        "\n",
        "    cfg[\"lr\"]           = random.choice([7e-4, 9e-4, 1e-3, 1.2e-3])\n",
        "    cfg[\"weight_decay\"] = random.choice([1e-4, 5e-4, 9e-4, 1.2e-3])\n",
        "    cfg[\"batch_size\"]   = random.choice([24, 32, 48])\n",
        "\n",
        "    cfg[\"T0\"]           = random.choice([70, 100, 120, 150])\n",
        "    cfg[\"Tmult\"]        = random.choice([1, 2])\n",
        "    cfg[\"swa_ratio\"]    = random.choice([0.25, 0.30, 0.33, 0.40])\n",
        "\n",
        "    cfg[\"alpha\"]        = random.choice([0.60, 0.65, 0.70, 0.80])\n",
        "    sup_w               = random.choice([0.90, 0.92, 0.95])\n",
        "    cfg[\"sup_weight\"]   = sup_w\n",
        "    cfg[\"recon_weight\"] = 1.0 - sup_w\n",
        "\n",
        "    cfg[\"ae_epochs\"]    = random.choice([80, 100, 120])\n",
        "    cfg[\"ae_feat_drop\"] = random.choice([0.05, 0.10, 0.15])\n",
        "\n",
        "    return cfg\n",
        "\n",
        "def quick_eval(cfg, dataset, bin_dim, cont_dim, hpo_ae_epochs=80, hpo_joint_epochs=220, seed_offset=0):\n",
        "    pt = fit_target_transform(dataset)\n",
        "    ae_init = pretrain_encoder(dataset, cfg, bin_dim, cont_dim, epochs_override=hpo_ae_epochs, seed=SEED + seed_offset)\n",
        "    model, va_loader = train_single_joint(dataset, pt, ae_init, cfg, seed_offset=seed_offset,\n",
        "                                          bin_dim=bin_dim, cont_dim=cont_dim, epochs_override=hpo_joint_epochs)\n",
        "    metrics = eval_ensemble([model], va_loader, pt)\n",
        "    return metrics, model\n",
        "\n",
        "def hpo_random_search(base_cfg, n_trials=20, hpo_ae_epochs=80, hpo_joint_epochs=220):\n",
        "    ds = GraphDataset(CSV_PATH, base_cfg, force_reprocess=base_cfg.get(\"force_reprocess\", False))\n",
        "    bin_dim, cont_dim = get_atom_feature_dims(base_cfg)\n",
        "\n",
        "    logs = []\n",
        "    best_cfg = None\n",
        "    best_met = None\n",
        "\n",
        "    for t in range(n_trials):\n",
        "        cfg = sample_cfg(base_cfg)\n",
        "        # IMPORTANT: create a fresh list copy for each trial to avoid y-transform compounding\n",
        "        trial_list = [ds[i] for i in range(len(ds))]\n",
        "\n",
        "        metrics, _ = quick_eval(cfg, trial_list, bin_dim, cont_dim,\n",
        "                                hpo_ae_epochs=hpo_ae_epochs,\n",
        "                                hpo_joint_epochs=hpo_joint_epochs,\n",
        "                                seed_offset=t*97)\n",
        "\n",
        "        logs.append({\"trial\": t, \"cfg\": cfg, \"metrics\": metrics})\n",
        "        print(f\"[HPO {t:02d}] R2={metrics['r2']:.4f}  MAE={metrics['mae']:.4f}  RMSE={metrics['rmse']:.4f}\")\n",
        "\n",
        "        if (best_met is None) or (metrics[\"r2\"] > best_met[\"r2\"] + 1e-6) or \\\n",
        "           (abs(metrics[\"r2\"] - best_met[\"r2\"]) < 1e-6 and metrics[\"mae\"] < best_met[\"mae\"]):\n",
        "            best_cfg = cfg\n",
        "            best_met = metrics\n",
        "\n",
        "    with open(HPO_LOG_PATH, \"w\") as f:\n",
        "        json.dump({\"logs\": logs, \"best_cfg\": best_cfg, \"best_metrics\": best_met}, f, indent=2)\n",
        "\n",
        "    print(f\"[HPO] Best R2={best_met['r2']:.4f}, MAE={best_met['mae']:.4f}, RMSE={best_met['rmse']:.4f}\")\n",
        "    return best_cfg, best_met\n",
        "\n",
        "# ---------------------------\n",
        "# Final Training (Full) + Ensemble\n",
        "# ---------------------------\n",
        "def run_pipeline(cfg):\n",
        "    print(\"Loading dataset...\")\n",
        "    ds = GraphDataset(CSV_PATH, cfg, force_reprocess=cfg.get(\"force_reprocess\", False))\n",
        "    ds_list = [ds[i] for i in range(len(ds))]  # list = safest for y-transform + HPO-like behavior\n",
        "\n",
        "    pt = fit_target_transform(ds_list)\n",
        "    joblib.dump(pt, PT_PATH)\n",
        "\n",
        "    bin_dim, cont_dim = get_atom_feature_dims(cfg)\n",
        "\n",
        "    print(\"Pretraining Graph Encoder (denoising recon)...\")\n",
        "    ae_init = pretrain_encoder(ds_list, cfg, bin_dim, cont_dim, epochs_override=cfg[\"ae_epochs\"], seed=SEED)\n",
        "\n",
        "    print(\"Joint fine-tuning + Ensemble...\")\n",
        "    models = []\n",
        "    val_loader_ref = None\n",
        "    for i in range(cfg[\"ensemble_size\"]):\n",
        "        m, v = train_single_joint(ds_list, pt, ae_init, cfg, seed_offset=i*123, bin_dim=bin_dim, cont_dim=cont_dim)\n",
        "        models.append(m)\n",
        "        val_loader_ref = v\n",
        "\n",
        "    metrics = eval_ensemble(models, val_loader_ref, pt)\n",
        "    return metrics, models, ae_init, pt\n",
        "\n",
        "# ---------------------------\n",
        "# Main\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== GRAPH JOINT AE + REGRESSOR + ENSEMBLE (with HPO) ===\")\n",
        "    print(\"Base config:\")\n",
        "    for k, v in BASE_CFG.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    print(\"\\n=== HPO: Random Search ===\")\n",
        "    best_cfg, best_hpo_metrics = hpo_random_search(\n",
        "        BASE_CFG,\n",
        "        n_trials=20,\n",
        "        hpo_ae_epochs=80,\n",
        "        hpo_joint_epochs=220\n",
        "    )\n",
        "\n",
        "    FINAL_CFG = dict(BASE_CFG)\n",
        "    FINAL_CFG.update(best_cfg)\n",
        "    FINAL_CFG[\"ae_epochs\"] = max(120, FINAL_CFG.get(\"ae_epochs\", BASE_CFG[\"ae_epochs\"]))\n",
        "    FINAL_CFG[\"epochs\"] = max(600, FINAL_CFG.get(\"epochs\", BASE_CFG[\"epochs\"]))\n",
        "    FINAL_CFG[\"ensemble_size\"] = BASE_CFG[\"ensemble_size\"]\n",
        "\n",
        "    print(\"\\n=== Final Training with Best Config (Full) ===\")\n",
        "    for k, v in FINAL_CFG.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    print(\"\\n=== 5-Fold Cross-Validation with Best Config ===\")\n",
        "    cv_summary, fold_metrics = run_cv_pipeline(FINAL_CFG, n_splits=5)\n",
        "\n",
        "    metrics, models, ae_init, pt = run_pipeline(FINAL_CFG)\n",
        "\n",
        "    print(\"\\nFinal Ensemble Metrics (Validation):\")\n",
        "    print(f\"  MAE:  {metrics['mae']:.4f}\")\n",
        "    print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
        "    print(f\"  MSE:  {metrics['mse']:.6f}\")\n",
        "    print(f\"  R²:   {metrics['r2']:.4f}\")\n",
        "\n",
        "    torch.save({\n",
        "        \"config\": FINAL_CFG,\n",
        "        \"best_hpo_metrics\": best_hpo_metrics,\n",
        "        \"power_transformer_path\": PT_PATH,\n",
        "        \"target_transform_lambdas\": getattr(pt, \"lambdas_\", None),\n",
        "        \"ae_encoder_state\": ae_init[\"encoder\"],\n",
        "        \"ae_decoder_state\": ae_init[\"decoder\"],\n",
        "        \"joint_states\": [m.state_dict() for m in models],\n",
        "    }, ARTIFACT_PATH)\n",
        "\n",
        "    print(f\"\\nSaved artifacts: {ARTIFACT_PATH}\")\n",
        "    print(f\"HPO log: {HPO_LOG_PATH}\")\n",
        "    print(f\"Target transform (for inference): {PT_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BFEiNzzRCRd",
        "outputId": "fe60634f-8b0b-4d20-be71-16ebae247f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GRAPH JOINT AE + REGRESSOR + ENSEMBLE (with HPO) ===\n",
            "Base config:\n",
            "  atom_nums: [1, 6, 7, 8, 9, 15, 16, 17, 35, 53]\n",
            "  max_degree: 5\n",
            "  charges: [-2, -1, 0, 1, 2]\n",
            "  hybs: [rdkit.Chem.rdchem.HybridizationType.SP, rdkit.Chem.rdchem.HybridizationType.SP2, rdkit.Chem.rdchem.HybridizationType.SP3, rdkit.Chem.rdchem.HybridizationType.SP3D, rdkit.Chem.rdchem.HybridizationType.SP3D2]\n",
            "  bond_types: [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE, rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]\n",
            "  force_reprocess: False\n",
            "  enc_hidden: 128\n",
            "  enc_layers: 3\n",
            "  enc_dropout: 0.1\n",
            "  ae_lr: 0.001\n",
            "  ae_weight_decay: 1e-05\n",
            "  ae_epochs: 150\n",
            "  ae_batch_size: 64\n",
            "  ae_feat_drop: 0.1\n",
            "  growth: 256\n",
            "  n_blocks: 4\n",
            "  dropout: 0.28\n",
            "  head_hidden: 384\n",
            "  lr: 0.00105\n",
            "  weight_decay: 0.0009\n",
            "  batch_size: 32\n",
            "  epochs: 600\n",
            "  T0: 70\n",
            "  Tmult: 1\n",
            "  swa_ratio: 0.33\n",
            "  alpha: 0.65\n",
            "  sup_weight: 0.9\n",
            "  recon_weight: 0.1\n",
            "  val_split: 0.1\n",
            "  ensemble_size: 10\n",
            "\n",
            "=== HPO: Random Search ===\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 132]), Regressor in_features: 132\n",
            "[HPO 00] R2=0.7644  MAE=0.0174  RMSE=0.0225\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 132]), Regressor in_features: 132\n",
            "[HPO 01] R2=0.8190  MAE=0.0112  RMSE=0.0143\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([48, 132]), Regressor in_features: 132\n",
            "[HPO 02] R2=0.5745  MAE=0.0214  RMSE=0.0268\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 196]), Regressor in_features: 196\n",
            "[HPO 03] R2=0.6170  MAE=0.0219  RMSE=0.0290\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 260]), Regressor in_features: 260\n",
            "[HPO 04] R2=0.5987  MAE=0.0222  RMSE=0.0315\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[HPO 05] R2=0.5254  MAE=0.0138  RMSE=0.0208\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([48, 228]), Regressor in_features: 228\n",
            "[HPO 06] R2=0.2030  MAE=0.0242  RMSE=0.0340\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 164]), Regressor in_features: 164\n",
            "[HPO 07] R2=0.6563  MAE=0.0237  RMSE=0.0296\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 164]), Regressor in_features: 164\n",
            "[HPO 08] R2=0.6943  MAE=0.0192  RMSE=0.0261\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 228]), Regressor in_features: 228\n",
            "[HPO 09] R2=0.4061  MAE=0.0178  RMSE=0.0262\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 164]), Regressor in_features: 164\n",
            "[HPO 10] R2=0.7346  MAE=0.0160  RMSE=0.0200\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([48, 196]), Regressor in_features: 196\n",
            "[HPO 11] R2=0.6444  MAE=0.0242  RMSE=0.0316\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 228]), Regressor in_features: 228\n",
            "[HPO 12] R2=0.5600  MAE=0.0236  RMSE=0.0308\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[HPO 13] R2=-1.2384  MAE=0.0273  RMSE=0.0338\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[HPO 14] R2=0.8275  MAE=0.0142  RMSE=0.0201\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 164]), Regressor in_features: 164\n",
            "[HPO 15] R2=0.4450  MAE=0.0167  RMSE=0.0224\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([48, 132]), Regressor in_features: 132\n",
            "[HPO 16] R2=-0.3249  MAE=0.0289  RMSE=0.0353\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([48, 260]), Regressor in_features: 260\n",
            "[HPO 17] R2=0.8134  MAE=0.0169  RMSE=0.0200\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([32, 196]), Regressor in_features: 196\n",
            "[HPO 18] R2=0.3907  MAE=0.0233  RMSE=0.0311\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 164]), Regressor in_features: 164\n",
            "[HPO 19] R2=0.7016  MAE=0.0170  RMSE=0.0217\n",
            "[HPO] Best R2=0.8275, MAE=0.0142, RMSE=0.0201\n",
            "\n",
            "=== Final Training with Best Config (Full) ===\n",
            "  atom_nums: [1, 6, 7, 8, 9, 15, 16, 17, 35, 53]\n",
            "  max_degree: 5\n",
            "  charges: [-2, -1, 0, 1, 2]\n",
            "  hybs: [rdkit.Chem.rdchem.HybridizationType.SP, rdkit.Chem.rdchem.HybridizationType.SP2, rdkit.Chem.rdchem.HybridizationType.SP3, rdkit.Chem.rdchem.HybridizationType.SP3D, rdkit.Chem.rdchem.HybridizationType.SP3D2]\n",
            "  bond_types: [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE, rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]\n",
            "  force_reprocess: False\n",
            "  enc_hidden: 192\n",
            "  enc_layers: 4\n",
            "  enc_dropout: 0.15\n",
            "  ae_lr: 0.001\n",
            "  ae_weight_decay: 1e-05\n",
            "  ae_epochs: 120\n",
            "  ae_batch_size: 64\n",
            "  ae_feat_drop: 0.1\n",
            "  growth: 256\n",
            "  n_blocks: 5\n",
            "  dropout: 0.1\n",
            "  head_hidden: 256\n",
            "  lr: 0.0009\n",
            "  weight_decay: 0.0001\n",
            "  batch_size: 24\n",
            "  epochs: 600\n",
            "  T0: 70\n",
            "  Tmult: 2\n",
            "  swa_ratio: 0.33\n",
            "  alpha: 0.7\n",
            "  sup_weight: 0.95\n",
            "  recon_weight: 0.050000000000000044\n",
            "  val_split: 0.1\n",
            "  ensemble_size: 10\n",
            "\n",
            "=== 5-Fold Cross-Validation with Best Config ===\n",
            "\n",
            "=== 5-Fold Cross-Validation ===\n",
            "\n",
            "--- Fold 1/5 ---\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[Fold 1] R²=0.4631  MAE=0.0230  RMSE=0.0315\n",
            "\n",
            "--- Fold 2/5 ---\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[Fold 2] R²=0.5896  MAE=0.0203  RMSE=0.0257\n",
            "\n",
            "--- Fold 3/5 ---\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[Fold 3] R²=0.3986  MAE=0.0280  RMSE=0.0362\n",
            "\n",
            "--- Fold 4/5 ---\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[Fold 4] R²=0.6032  MAE=0.0184  RMSE=0.0226\n",
            "\n",
            "--- Fold 5/5 ---\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[Fold 5] R²=0.4606  MAE=0.0205  RMSE=0.0278\n",
            "\n",
            "=== CV Summary ===\n",
            "R²:   0.5030 ± 0.0798\n",
            "MAE:  0.0221 ± 0.0033\n",
            "RMSE: 0.0288 ± 0.0047\n",
            "Loading dataset...\n",
            "Pretraining Graph Encoder (denoising recon)...\n",
            "Joint fine-tuning + Ensemble...\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "[DEBUG] Epoch 0 — z_graph: torch.Size([24, 196]), Regressor in_features: 196\n",
            "\n",
            "Final Ensemble Metrics (Validation):\n",
            "  MAE:  0.0096\n",
            "  RMSE: 0.0124\n",
            "  MSE:  0.000155\n",
            "  R²:   0.9217\n",
            "\n",
            "Saved artifacts: option4b_graph_joint_ae_regressor_ensemble.pt\n",
            "HPO log: graph_hpo_log.json\n",
            "Target transform (for inference): target_transform.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAL89tOfWnxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Path\n",
        "# ---------------------------\n",
        "EXT_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/External_VALID.csv\"\n",
        "\n",
        "# ---------------------------\n",
        "# Load dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv(EXT_PATH)\n",
        "\n",
        "# ---------------------------\n",
        "# Rename columns (consistent naming)\n",
        "# ---------------------------\n",
        "df = df.rename(columns={\n",
        "    \"SMILES\": \"SMILES(modred)\",\n",
        "    \"Block_A\": \"Block A (x)\",\n",
        "    \"Block_B\": \"Block B (1-x)\",\n",
        "    \"A/B_ratio\": \"Block A/B ratio\",\n",
        "    \"polymer_type\": \"Polymer type\",\n",
        "    \"conductivity\": \"Membrane Anion Conductivity [S/cm]\"\n",
        "})\n",
        "\n",
        "# ---------------------------\n",
        "# Normalize block fractions\n",
        "# ---------------------------\n",
        "#df[\"Block A (x)\"] = df[\"Block A (x)\"].astype(float) / 100.0\n",
        "#df[\"Block B (1-x)\"] = df[\"Block B (1-x)\"].astype(float) / 100.0\n",
        "\n",
        "# ---------------------------\n",
        "# Define polymer identity\n",
        "# ---------------------------\n",
        "group_cols = [\n",
        "    \"SMILES(modred)\",\n",
        "    \"Block A (x)\",\n",
        "    \"Block B (1-x)\",\n",
        "    \"Block A/B ratio\",\n",
        "    \"Polymer type\"\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# Aggregate: mean conductivity ONLY\n",
        "# ---------------------------\n",
        "polymer_df = (\n",
        "    df.groupby(group_cols, as_index=False)\n",
        "      .agg({\"Membrane Anion Conductivity [S/cm]\": \"mean\"})\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Save\n",
        "# ---------------------------\n",
        "OUT_PATH = (\n",
        "    \"/content/drive/MyDrive/Pegah_works/validation_datasset/\"\n",
        "    \"External_VALID_POLYMER_MEAN_ONLY.csv\"\n",
        ")\n",
        "polymer_df.to_csv(OUT_PATH, index=False)\n",
        "\n",
        "print(f\"Saved polymer-level mean dataset with {len(polymer_df)} polymers:\")\n",
        "print(OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e872160-75d2-4755-e1f4-9f36218f0486",
        "id": "UwK7BcaVeOrp"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved polymer-level mean dataset with 20 polymers:\n",
            "/content/drive/MyDrive/Pegah_works/validation_datasset/External_VALID_POLYMER_MEAN_ONLY.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# External Dataset Examination ONLY (NO MODEL, NO PREDICTION)\n",
        "# ===========================================================\n",
        "# - Target distribution\n",
        "# - Replicate structure\n",
        "# - Experimental spread within replicates\n",
        "# - Saves clean summary CSVs\n",
        "# ===========================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Path\n",
        "# ---------------------------\n",
        "EXT_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/modified_data_final_2.csv\"\n",
        "\n",
        "# ---------------------------\n",
        "# Load dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv(EXT_PATH)\n",
        "\n",
        "# ---------------------------\n",
        "# Rename columns (exactly as used earlier)\n",
        "# ---------------------------\n",
        "df = df.rename(columns={\n",
        "    \"SMILES\": \"SMILES(modred)\",\n",
        "    \"Block_A\": \"Block A (x)\",\n",
        "    \"Block_B\": \"Block B (1-x)\",\n",
        "    \"A/B_ratio\": \"Block A/B ratio\",\n",
        "    \"polymer_type\": \"Polymer type\",\n",
        "    \"conductivity\": \"Membrane Anion Conductivity [S/cm]\"\n",
        "})\n",
        "\n",
        "# ---------------------------\n",
        "# Normalize block fractions\n",
        "# ---------------------------\n",
        "df[\"Block A (x)\"] = df[\"Block A (x)\"].astype(float) / 100.0\n",
        "df[\"Block B (1-x)\"] = df[\"Block B (1-x)\"].astype(float) / 100.0\n",
        "\n",
        "# ---------------------------\n",
        "# Basic sanity checks\n",
        "# ---------------------------\n",
        "print(\"\\n=== Dataset shape ===\")\n",
        "print(df.shape)\n",
        "\n",
        "print(\"\\n=== First 5 rows ===\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n=== Block sum check (should be 1.0) ===\")\n",
        "print((df[\"Block A (x)\"] + df[\"Block B (1-x)\"]).describe())\n",
        "\n",
        "# ---------------------------\n",
        "# Target distribution\n",
        "# ---------------------------\n",
        "y = df[\"Membrane Anion Conductivity [S/cm]\"].astype(float).values\n",
        "\n",
        "print(\"\\n=== Target distribution (External dataset) ===\")\n",
        "print(f\"Count : {len(y)}\")\n",
        "print(f\"Min   : {y.min():.6f}\")\n",
        "print(f\"Max   : {y.max():.6f}\")\n",
        "print(f\"Mean  : {y.mean():.6f}\")\n",
        "print(f\"Std   : {y.std(ddof=0):.6f}  (population)\")\n",
        "print(f\"Std   : {y.std(ddof=1):.6f}  (sample)\")\n",
        "\n",
        "# ---------------------------\n",
        "# Define replicate identity (what makes a polymer unique)\n",
        "# ---------------------------\n",
        "group_cols = [\n",
        "    \"SMILES(modred)\",\n",
        "    \"Block A (x)\",\n",
        "    \"Block B (1-x)\",\n",
        "    \"Block A/B ratio\",\n",
        "    \"Polymer type\"\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# Replicate counts\n",
        "# ---------------------------\n",
        "rep_counts = (\n",
        "    df.groupby(group_cols)\n",
        "      .size()\n",
        "      .reset_index(name=\"n_measurements\")\n",
        ")\n",
        "\n",
        "print(\"\\n=== Replicate counts per unique polymer ===\")\n",
        "print(\"Unique polymers:\", len(rep_counts))\n",
        "print(rep_counts[\"n_measurements\"].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nFraction of dataset with replicates (>1 measurement):\")\n",
        "frac_rep = rep_counts.loc[rep_counts[\"n_measurements\"] > 1, \"n_measurements\"].sum() / len(df)\n",
        "print(f\"{frac_rep*100:.1f}%\")\n",
        "\n",
        "# ---------------------------\n",
        "# Experimental spread within replicates\n",
        "# ---------------------------\n",
        "spread = (\n",
        "    df.groupby(group_cols)\n",
        "      .agg(\n",
        "          n=(\"Membrane Anion Conductivity [S/cm]\", \"size\"),\n",
        "          y_mean=(\"Membrane Anion Conductivity [S/cm]\", \"mean\"),\n",
        "          y_std=(\"Membrane Anion Conductivity [S/cm]\", \"std\"),\n",
        "          y_min=(\"Membrane Anion Conductivity [S/cm]\", \"min\"),\n",
        "          y_max=(\"Membrane Anion Conductivity [S/cm]\", \"max\"),\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Fill NaN std for single-measurement polymers\n",
        "spread[\"y_std\"] = spread[\"y_std\"].fillna(0.0)\n",
        "spread[\"y_range\"] = spread[\"y_max\"] - spread[\"y_min\"]\n",
        "\n",
        "print(\"\\n=== Experimental variability (within same polymer) ===\")\n",
        "print(f\"Median std   : {np.median(spread['y_std']):.6f}\")\n",
        "print(f\"Mean std     : {np.mean(spread['y_std']):.6f}\")\n",
        "print(f\"Median range: {np.median(spread['y_range']):.6f}\")\n",
        "print(f\"Mean range  : {np.mean(spread['y_range']):.6f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Most variable polymers\n",
        "# ---------------------------\n",
        "print(\"\\n=== Top 10 most variable polymers (by range) ===\")\n",
        "print(\n",
        "    spread.sort_values(\"y_range\", ascending=False)\n",
        "          .head(10)[\n",
        "              [\n",
        "                  \"SMILES(modred)\",\n",
        "                  \"Block A (x)\",\n",
        "                  \"Block B (1-x)\",\n",
        "                  \"Block A/B ratio\",\n",
        "                  \"Polymer type\",\n",
        "                  \"n\",\n",
        "                  \"y_mean\",\n",
        "                  \"y_std\",\n",
        "                  \"y_min\",\n",
        "                  \"y_max\",\n",
        "                  \"y_range\"\n",
        "              ]\n",
        "          ]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Save clean summaries\n",
        "# ---------------------------\n",
        "#rep_counts.to_csv(\"external_replicate_counts.csv\", index=False)\n",
        "#spread.to_csv(\"external_experimental_spread.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df7b1e7-42fa-4610-ca1c-2092b9a052ff",
        "id": "k4WFIBzbZIdZ"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dataset shape ===\n",
            "(207, 6)\n",
            "\n",
            "=== First 5 rows ===\n",
            "                                      SMILES(modred)  Block A (x)  \\\n",
            "0  CC1=CC=C(C=C1)C(C2=CC=C(C=C2)OC3=CC=C(C=C3)C(C...     0.001980   \n",
            "1  CC1=CC=C(C(C2=CC=C(OC3=CC=C(C(C)(CCC(NCC4=CC=[...     0.005020   \n",
            "2  CC1=CC=C(C(C2=CC=C(OC3=CC=C(C(C)(CCC(NCC4=CC=[...     0.007581   \n",
            "3  CC1=CC=C(C(C2=CC=C(OC3=CC=C(C(C)(CCC(NCC4=CC=[...     0.009670   \n",
            "4  COC1=C(C[N+]2=C(CC)N=CC2)C=C(OC3=CC(C[N+]4=C(C...     0.001500   \n",
            "\n",
            "   Block B (1-x)  Block A/B ratio  Polymer type  \\\n",
            "0       0.008020            0.247             1   \n",
            "1       0.004980            1.008             1   \n",
            "2       0.002419            3.134             1   \n",
            "3       0.000330           29.303             1   \n",
            "4       0.008500            0.176             1   \n",
            "\n",
            "   Membrane Anion Conductivity [S/cm]  \n",
            "0                             0.00318  \n",
            "1                             0.00616  \n",
            "2                             0.01026  \n",
            "3                             0.01156  \n",
            "4                             0.01700  \n",
            "\n",
            "=== Block sum check (should be 1.0) ===\n",
            "count    207.000000\n",
            "mean       0.009665\n",
            "std        0.001680\n",
            "min        0.001042\n",
            "25%        0.010000\n",
            "50%        0.010000\n",
            "75%        0.010000\n",
            "max        0.010100\n",
            "dtype: float64\n",
            "\n",
            "=== Target distribution (External dataset) ===\n",
            "Count : 207\n",
            "Min   : 0.001150\n",
            "Max   : 0.178190\n",
            "Mean  : 0.063995\n",
            "Std   : 0.041661  (population)\n",
            "Std   : 0.041762  (sample)\n",
            "\n",
            "=== Replicate counts per unique polymer ===\n",
            "Unique polymers: 201\n",
            "n_measurements\n",
            "1    196\n",
            "2      4\n",
            "3      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Fraction of dataset with replicates (>1 measurement):\n",
            "5.3%\n",
            "\n",
            "=== Experimental variability (within same polymer) ===\n",
            "Median std   : 0.000000\n",
            "Mean std     : 0.000265\n",
            "Median range: 0.000000\n",
            "Mean range  : 0.000396\n",
            "\n",
            "=== Top 10 most variable polymers (by range) ===\n",
            "                                        SMILES(modred)  Block A (x)  \\\n",
            "124  CC1=CC=C(S(C2=CC=C(OC3=C(C)C=C(S(C4=CC(C)=C(OC...      0.00474   \n",
            "65   CC1=CC(C)=C(OC2=CC(CN3N=NC(C[N+](C)(C)CCCC)=C3...      0.00300   \n",
            "123  CC1=CC=C(S(C2=CC=C(OC3=C(C)C=C(S(C4=CC(C)=C(OC...      0.00385   \n",
            "122  CC1=CC=C(S(C2=CC=C(OC3=C(C)C=C(S(C4=CC(C)=C(OC...      0.00333   \n",
            "64   CC1=CC(C)=C(OC2=CC(CN3N=NC(C[N+](C)(C)CCCC)=C3...      0.00200   \n",
            "5    C=S(C1=CC=C(OC2=CC=C(C3=CC=C(C)C=C3)C=C2)C=C1)...      0.00340   \n",
            "2    C=S(C1=CC=C(OC2=CC=C(C3=CC=C(C)C=C3)C=C2)C=C1)...      0.00250   \n",
            "1    C=S(C1=CC=C(OC2=C(C[N+]3(C)CCCCC3)C=C(OCC=C)C(...      0.00600   \n",
            "4    C=S(C1=CC=C(OC2=CC=C(C3=CC=C(C)C=C3)C=C2)C=C1)...      0.00280   \n",
            "8    CC(C1=CC(C[N+](C)(C)C)=C(OC2=CC=C(C(C3=CC=C(C(...      0.00296   \n",
            "\n",
            "     Block B (1-x)  Block A/B ratio  Polymer type  n    y_mean     y_std  \\\n",
            "124        0.00526            0.901             1  2  0.049900  0.020082   \n",
            "65         0.00700            0.429             1  2  0.031750  0.013081   \n",
            "123        0.00615            0.626             1  2  0.046150  0.011809   \n",
            "122        0.00667            0.499             1  3  0.051433  0.007200   \n",
            "64         0.00800            0.160             1  2  0.010600  0.001131   \n",
            "5          0.00660            0.515             1  1  0.035900  0.000000   \n",
            "2          0.00750            0.333             1  1  0.036100  0.000000   \n",
            "1          0.00400            1.500             1  1  0.078300  0.000000   \n",
            "4          0.00720            0.389             1  1  0.030900  0.000000   \n",
            "8          0.00704            0.420             1  1  0.025400  0.000000   \n",
            "\n",
            "      y_min   y_max  y_range  \n",
            "124  0.0357  0.0641   0.0284  \n",
            "65   0.0225  0.0410   0.0185  \n",
            "123  0.0378  0.0545   0.0167  \n",
            "122  0.0442  0.0586   0.0144  \n",
            "64   0.0098  0.0114   0.0016  \n",
            "5    0.0359  0.0359   0.0000  \n",
            "2    0.0361  0.0361   0.0000  \n",
            "1    0.0783  0.0783   0.0000  \n",
            "4    0.0309  0.0309   0.0000  \n",
            "8    0.0254  0.0254   0.0000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# External Dataset Examination ONLY (NO MODEL, NO PREDICTION)\n",
        "# ===========================================================\n",
        "# - Target distribution\n",
        "# - Replicate structure\n",
        "# - Experimental spread within replicates\n",
        "# - Saves clean summary CSVs\n",
        "# ===========================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Path\n",
        "# ---------------------------\n",
        "EXT_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/External_VALID_POLYMER_MEAN_ONLY.csv\"\n",
        "\n",
        "# ---------------------------\n",
        "# Load dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv(EXT_PATH)\n",
        "\n",
        "# ---------------------------\n",
        "# Rename columns (exactly as used earlier)\n",
        "# ---------------------------\n",
        "df = df.rename(columns={\n",
        "    \"SMILES\": \"SMILES(modred)\",\n",
        "    \"Block_A\": \"Block A (x)\",\n",
        "    \"Block_B\": \"Block B (1-x)\",\n",
        "    \"A/B_ratio\": \"Block A/B ratio\",\n",
        "    \"polymer_type\": \"Polymer type\",\n",
        "    \"conductivity\": \"Membrane Anion Conductivity [S/cm]\"\n",
        "})\n",
        "\n",
        "# ---------------------------\n",
        "# Normalize block fractions\n",
        "# ---------------------------\n",
        "df[\"Block A (x)\"] = df[\"Block A (x)\"].astype(float) / 100.0\n",
        "df[\"Block B (1-x)\"] = df[\"Block B (1-x)\"].astype(float) / 100.0\n",
        "\n",
        "# ---------------------------\n",
        "# Basic sanity checks\n",
        "# ---------------------------\n",
        "print(\"\\n=== Dataset shape ===\")\n",
        "print(df.shape)\n",
        "\n",
        "print(\"\\n=== First 5 rows ===\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n=== Block sum check (should be 1.0) ===\")\n",
        "print((df[\"Block A (x)\"] + df[\"Block B (1-x)\"]).describe())\n",
        "\n",
        "# ---------------------------\n",
        "# Target distribution\n",
        "# ---------------------------\n",
        "y = df[\"Membrane Anion Conductivity [S/cm]\"].astype(float).values\n",
        "\n",
        "print(\"\\n=== Target distribution (External dataset) ===\")\n",
        "print(f\"Count : {len(y)}\")\n",
        "print(f\"Min   : {y.min():.6f}\")\n",
        "print(f\"Max   : {y.max():.6f}\")\n",
        "print(f\"Mean  : {y.mean():.6f}\")\n",
        "print(f\"Std   : {y.std(ddof=0):.6f}  (population)\")\n",
        "print(f\"Std   : {y.std(ddof=1):.6f}  (sample)\")\n",
        "\n",
        "# ---------------------------\n",
        "# Define replicate identity (what makes a polymer unique)\n",
        "# ---------------------------\n",
        "group_cols = [\n",
        "    \"SMILES(modred)\",\n",
        "    \"Block A (x)\",\n",
        "    \"Block B (1-x)\",\n",
        "    \"Block A/B ratio\",\n",
        "    \"Polymer type\"\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# Replicate counts\n",
        "# ---------------------------\n",
        "rep_counts = (\n",
        "    df.groupby(group_cols)\n",
        "      .size()\n",
        "      .reset_index(name=\"n_measurements\")\n",
        ")\n",
        "\n",
        "print(\"\\n=== Replicate counts per unique polymer ===\")\n",
        "print(\"Unique polymers:\", len(rep_counts))\n",
        "print(rep_counts[\"n_measurements\"].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nFraction of dataset with replicates (>1 measurement):\")\n",
        "frac_rep = rep_counts.loc[rep_counts[\"n_measurements\"] > 1, \"n_measurements\"].sum() / len(df)\n",
        "print(f\"{frac_rep*100:.1f}%\")\n",
        "\n",
        "# ---------------------------\n",
        "# Experimental spread within replicates\n",
        "# ---------------------------\n",
        "spread = (\n",
        "    df.groupby(group_cols)\n",
        "      .agg(\n",
        "          n=(\"Membrane Anion Conductivity [S/cm]\", \"size\"),\n",
        "          y_mean=(\"Membrane Anion Conductivity [S/cm]\", \"mean\"),\n",
        "          y_std=(\"Membrane Anion Conductivity [S/cm]\", \"std\"),\n",
        "          y_min=(\"Membrane Anion Conductivity [S/cm]\", \"min\"),\n",
        "          y_max=(\"Membrane Anion Conductivity [S/cm]\", \"max\"),\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Fill NaN std for single-measurement polymers\n",
        "spread[\"y_std\"] = spread[\"y_std\"].fillna(0.0)\n",
        "spread[\"y_range\"] = spread[\"y_max\"] - spread[\"y_min\"]\n",
        "\n",
        "print(\"\\n=== Experimental variability (within same polymer) ===\")\n",
        "print(f\"Median std   : {np.median(spread['y_std']):.6f}\")\n",
        "print(f\"Mean std     : {np.mean(spread['y_std']):.6f}\")\n",
        "print(f\"Median range: {np.median(spread['y_range']):.6f}\")\n",
        "print(f\"Mean range  : {np.mean(spread['y_range']):.6f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Most variable polymers\n",
        "# ---------------------------\n",
        "print(\"\\n=== Top 10 most variable polymers (by range) ===\")\n",
        "print(\n",
        "    spread.sort_values(\"y_range\", ascending=False)\n",
        "          .head(10)[\n",
        "              [\n",
        "                  \"SMILES(modred)\",\n",
        "                  \"Block A (x)\",\n",
        "                  \"Block B (1-x)\",\n",
        "                  \"Block A/B ratio\",\n",
        "                  \"Polymer type\",\n",
        "                  \"n\",\n",
        "                  \"y_mean\",\n",
        "                  \"y_std\",\n",
        "                  \"y_min\",\n",
        "                  \"y_max\",\n",
        "                  \"y_range\"\n",
        "              ]\n",
        "          ]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Save clean summaries\n",
        "# ---------------------------\n",
        "#rep_counts.to_csv(\"external_replicate_counts.csv\", index=False)\n",
        "#spread.to_csv(\"external_experimental_spread.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved files:\")\n",
        "print(\" - external_replicate_counts.csv\")\n",
        "print(\" - external_experimental_spread.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f818dab8-a704-4716-c36e-fd5df7ab505b",
        "id": "PmzQBW4yYbF1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dataset shape ===\n",
            "(20, 6)\n",
            "\n",
            "=== First 5 rows ===\n",
            "                                      SMILES(modred)  Block A (x)  \\\n",
            "0                         C(C)C[N+](C)(C)CCCCCCNC(C)         0.87   \n",
            "1                      C(C)C[N+]1(CCCCCCNC(C))CCCCC1         0.87   \n",
            "2  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.64   \n",
            "3  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.67   \n",
            "4  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.73   \n",
            "\n",
            "   Block B (1-x)  Block A/B ratio  Polymer type  \\\n",
            "0           0.13         6.692308           1.0   \n",
            "1           0.13         6.692308           1.0   \n",
            "2           0.36         1.777778           1.0   \n",
            "3           0.33         2.030303           1.0   \n",
            "4           0.27         2.703704           1.0   \n",
            "\n",
            "   Membrane Anion Conductivity [S/cm]  \n",
            "0                             0.08217  \n",
            "1                             0.04349  \n",
            "2                             0.01290  \n",
            "3                             0.01860  \n",
            "4                             0.02950  \n",
            "\n",
            "=== Block sum check (should be 1.0) ===\n",
            "count    20.000000\n",
            "mean      0.999000\n",
            "std       0.003078\n",
            "min       0.990000\n",
            "25%       1.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n",
            "dtype: float64\n",
            "\n",
            "=== Target distribution (External dataset) ===\n",
            "Count : 20\n",
            "Min   : 0.010928\n",
            "Max   : 0.098000\n",
            "Mean  : 0.037795\n",
            "Std   : 0.023618  (population)\n",
            "Std   : 0.024231  (sample)\n",
            "\n",
            "=== Replicate counts per unique polymer ===\n",
            "Unique polymers: 20\n",
            "n_measurements\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Fraction of dataset with replicates (>1 measurement):\n",
            "0.0%\n",
            "\n",
            "=== Experimental variability (within same polymer) ===\n",
            "Median std   : 0.000000\n",
            "Mean std     : 0.000000\n",
            "Median range: 0.000000\n",
            "Mean range  : 0.000000\n",
            "\n",
            "=== Top 10 most variable polymers (by range) ===\n",
            "                                      SMILES(modred)  Block A (x)  \\\n",
            "0                         C(C)C[N+](C)(C)CCCCCCNC(C)         0.87   \n",
            "1                      C(C)C[N+]1(CCCCCCNC(C))CCCCC1         0.87   \n",
            "2  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.64   \n",
            "3  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.67   \n",
            "4  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.73   \n",
            "5  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.75   \n",
            "6  CC(C)(C)c1ccc(C(C))cc1 CC(CCCC(CC(C)CCC)c2ccc(...         0.30   \n",
            "7                   CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.59   \n",
            "8                   CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.68   \n",
            "9                   CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.80   \n",
            "\n",
            "   Block B (1-x)  Block A/B ratio  Polymer type  n    y_mean  y_std     y_min  \\\n",
            "0           0.13         6.692308           1.0  1  0.082170    0.0  0.082170   \n",
            "1           0.13         6.692308           1.0  1  0.043490    0.0  0.043490   \n",
            "2           0.36         1.777778           1.0  1  0.012900    0.0  0.012900   \n",
            "3           0.33         2.030303           1.0  1  0.018600    0.0  0.018600   \n",
            "4           0.27         2.703704           1.0  1  0.029500    0.0  0.029500   \n",
            "5           0.25         3.000000           1.0  1  0.041460    0.0  0.041460   \n",
            "6           0.70         0.428571           1.0  1  0.098000    0.0  0.098000   \n",
            "7           0.41         1.439024           1.0  1  0.059933    0.0  0.059933   \n",
            "8           0.32         2.125000           1.0  1  0.056560    0.0  0.056560   \n",
            "9           0.20         4.000000           1.0  1  0.040420    0.0  0.040420   \n",
            "\n",
            "      y_max  y_range  \n",
            "0  0.082170      0.0  \n",
            "1  0.043490      0.0  \n",
            "2  0.012900      0.0  \n",
            "3  0.018600      0.0  \n",
            "4  0.029500      0.0  \n",
            "5  0.041460      0.0  \n",
            "6  0.098000      0.0  \n",
            "7  0.059933      0.0  \n",
            "8  0.056560      0.0  \n",
            "9  0.040420      0.0  \n",
            "\n",
            "Saved files:\n",
            " - external_replicate_counts.csv\n",
            " - external_experimental_spread.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# External Inference + Ensemble Metrics (FINAL – SWA unwrap + PT2.6 load)\n",
        "# ===========================================================\n",
        "# Fixes in this version:\n",
        "# 1) torch.load: PT 2.6 -> must use weights_only=False for your checkpoint\n",
        "# 2) SWA AveragedModel state_dict keys are prefixed with \"module.\" and include \"n_averaged\"\n",
        "#    -> we unwrap keys before loading into a normal nn.Module\n",
        "# 3) Your saved BN keys show \"encoder.bns.X.module.*\" (from PyG BatchNorm wrapper)\n",
        "#    -> model definition matches your TRAINING model exactly (with BatchNorm from torch_geometric.nn)\n",
        "# 4) node_in/edge_in are computed from config (no fragile state_dict probing)\n",
        "# ===========================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import rdchem\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool, BatchNorm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Paths\n",
        "# -----------------------------------------------------------\n",
        "ARTIFACT_PATH = \"option4b_graph_joint_ae_regressor_ensemble.pt\"\n",
        "PT_PATH = \"target_transform.joblib\"\n",
        "EXT_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/External_VALID_POLYMER_MEAN_ONLY.csv\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load checkpoint (trusted)\n",
        "# -----------------------------------------------------------\n",
        "ckpt = torch.load(ARTIFACT_PATH, map_location=device, weights_only=False)\n",
        "FINAL_CFG = ckpt[\"config\"]\n",
        "joint_states = ckpt[\"joint_states\"]\n",
        "pt = joblib.load(PT_PATH)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Unwrap SWA / DDP-ish state_dict (module. prefix + n_averaged)\n",
        "# -----------------------------------------------------------\n",
        "def unwrap_swa_state_dict(state_dict):\n",
        "    new_sd = {}\n",
        "    for k, v in state_dict.items():\n",
        "        if k == \"n_averaged\":\n",
        "            continue\n",
        "        if k.startswith(\"module.\"):\n",
        "            k = k[len(\"module.\"):]\n",
        "        new_sd[k] = v\n",
        "    return new_sd\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Feature dims (match training)\n",
        "# -----------------------------------------------------------\n",
        "def get_atom_feature_dims(cfg):\n",
        "    bin_dim = (\n",
        "        (len(cfg[\"atom_nums\"]) + 1) +\n",
        "        (cfg[\"max_degree\"] + 1 + 1) +\n",
        "        (len(cfg[\"charges\"]) + 1) +\n",
        "        (len(cfg[\"hybs\"]) + 1) +\n",
        "        2\n",
        "    )\n",
        "    cont_dim = 2\n",
        "    return bin_dim + cont_dim\n",
        "\n",
        "def get_edge_feature_dims(cfg):\n",
        "    return len(cfg[\"bond_types\"]) + 1 + 2\n",
        "\n",
        "node_in = get_atom_feature_dims(FINAL_CFG)\n",
        "edge_in = get_edge_feature_dims(FINAL_CFG)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Feature functions (IDENTICAL to training)\n",
        "# -----------------------------------------------------------\n",
        "def atom_features(atom, cfg):\n",
        "    nums, hybs, charges, max_deg = cfg[\"atom_nums\"], cfg[\"hybs\"], cfg[\"charges\"], cfg[\"max_degree\"]\n",
        "    f_num = [1.0 if atom.GetAtomicNum() == z else 0.0 for z in nums] + [0.0]\n",
        "    if sum(f_num[:-1]) == 0:\n",
        "        f_num[-1] = 1.0\n",
        "\n",
        "    d = atom.GetTotalDegree()\n",
        "    f_deg = [1.0 if d == k else 0.0 for k in range(max_deg + 1)] + [1.0 if d > max_deg else 0.0]\n",
        "\n",
        "    ch = atom.GetFormalCharge()\n",
        "    f_ch = [1.0 if ch == c else 0.0 for c in charges] + [1.0 if ch not in charges else 0.0]\n",
        "\n",
        "    hyb = atom.GetHybridization()\n",
        "    f_hy = [1.0 if hyb == h else 0.0 for h in hybs] + [1.0 if hyb not in hybs else 0.0]\n",
        "\n",
        "    f_bin_misc = [float(atom.GetIsAromatic()), float(atom.IsInRing())]\n",
        "    f_cont = [float(atom.GetTotalNumHs(includeNeighbors=True)),\n",
        "              float(atom.GetImplicitValence())]\n",
        "    return np.array(f_num + f_deg + f_ch + f_hy + f_bin_misc + f_cont, dtype=np.float32)\n",
        "\n",
        "def bond_features(bond, cfg):\n",
        "    btypes = cfg[\"bond_types\"]\n",
        "    f_bt = [1.0 if bond.GetBondType() == t else 0.0 for t in btypes] + [0.0]\n",
        "    if sum(f_bt[:-1]) == 0:\n",
        "        f_bt[-1] = 1.0\n",
        "    f_misc = [float(bond.GetIsConjugated()), float(bond.IsInRing())]\n",
        "    return np.array(f_bt + f_misc, dtype=np.float32)\n",
        "\n",
        "def smiles_to_pyg(smiles, cfg):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    Chem.Kekulize(mol, clearAromaticFlags=False)\n",
        "\n",
        "    x = torch.tensor(np.vstack([atom_features(a, cfg) for a in mol.GetAtoms()]), dtype=torch.float32)\n",
        "\n",
        "    ei_src, ei_dst, eattr = [], [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        bf = bond_features(b, cfg)\n",
        "        ei_src += [i, j]\n",
        "        ei_dst += [j, i]\n",
        "        eattr.append(bf)\n",
        "        eattr.append(bf)\n",
        "\n",
        "    if len(ei_src) == 0:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, edge_in), dtype=torch.float32)\n",
        "    else:\n",
        "        edge_index = torch.tensor([ei_src, ei_dst], dtype=torch.long)\n",
        "        edge_attr = torch.tensor(np.vstack(eattr), dtype=torch.float32)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Model definitions (MATCH YOUR TRAINING ARCHITECTURE)\n",
        "# IMPORTANT: includes decoder + SE regressor blocks exactly\n",
        "# -----------------------------------------------------------\n",
        "class GNNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, layers, dropout, edge_dim):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        last = in_dim\n",
        "        for _ in range(layers):\n",
        "            mlp = nn.Sequential(nn.Linear(last, hidden), nn.ReLU(), nn.Linear(hidden, hidden))\n",
        "            self.convs.append(GINEConv(mlp, edge_dim=edge_dim))\n",
        "            self.bns.append(BatchNorm(hidden))\n",
        "            last = hidden\n",
        "        self.dropout = dropout\n",
        "        self.out_dim = hidden\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        for conv, bn in zip(self.convs, self.bns):\n",
        "            x = conv(x, edge_index, edge_attr)\n",
        "            x = bn(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "class NodeFeatDecoder(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_dim, out_dim)\n",
        "        )\n",
        "    def forward(self, h_nodes):\n",
        "        return self.net(h_nodes)\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, dim, reduction=8):\n",
        "        super().__init__()\n",
        "        hidden = max(4, dim // reduction)\n",
        "        self.fc1 = nn.Linear(dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, dim)\n",
        "    def forward(self, x):\n",
        "        w = torch.sigmoid(self.fc2(F.relu(self.fc1(x))))\n",
        "        return x * w\n",
        "\n",
        "class DenseSERegressor(nn.Module):\n",
        "    def __init__(self, in_dim, growth, n_blocks, dropout, head_hidden):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Sequential(\n",
        "            nn.Linear(in_dim, growth),\n",
        "            nn.BatchNorm1d(growth),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        ))\n",
        "        for _ in range(n_blocks - 1):\n",
        "            layers.append(nn.Sequential(\n",
        "                nn.Linear(growth, growth),\n",
        "                nn.BatchNorm1d(growth),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "        self.se = SEBlock(growth, reduction=8)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(growth, head_hidden),\n",
        "            nn.BatchNorm1d(head_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(head_hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.blocks(z)\n",
        "        h = self.se(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class JointGraphAER(nn.Module):\n",
        "    def __init__(self, node_in, edge_in, cfg, num_extra_feats=4):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(node_in, cfg[\"enc_hidden\"], cfg[\"enc_layers\"], cfg[\"enc_dropout\"], edge_in)\n",
        "        self.decoder = NodeFeatDecoder(cfg[\"enc_hidden\"], node_in)\n",
        "        self.num_extra_feats = num_extra_feats\n",
        "        self.regressor = DenseSERegressor(\n",
        "            in_dim=cfg[\"enc_hidden\"] + num_extra_feats,\n",
        "            growth=cfg[\"growth\"],\n",
        "            n_blocks=cfg[\"n_blocks\"],\n",
        "            dropout=cfg[\"dropout\"],\n",
        "            head_hidden=cfg[\"head_hidden\"]\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        h_nodes = self.encoder(data.x, data.edge_index, data.edge_attr)\n",
        "        z_graph = global_mean_pool(h_nodes, data.batch)\n",
        "\n",
        "        nf = data.num_feats.to(z_graph.device)\n",
        "        if nf.dim() == 1:\n",
        "            nf = nf.view(z_graph.size(0), -1)\n",
        "\n",
        "        if nf.size(1) > self.num_extra_feats:\n",
        "            nf = nf[:, :self.num_extra_feats]\n",
        "        elif nf.size(1) < self.num_extra_feats:\n",
        "            pad = torch.zeros(z_graph.size(0), self.num_extra_feats - nf.size(1), device=z_graph.device)\n",
        "            nf = torch.cat([nf, pad], dim=1)\n",
        "\n",
        "        z_graph = torch.cat([z_graph, nf], dim=1)\n",
        "\n",
        "        y_hat = self.regressor(z_graph)\n",
        "        x_logits = self.decoder(h_nodes)\n",
        "        return y_hat, x_logits, h_nodes, z_graph\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load ensemble models (unwrap SWA keys first)\n",
        "# -----------------------------------------------------------\n",
        "models = []\n",
        "for state in joint_states:\n",
        "    sd = unwrap_swa_state_dict(state)\n",
        "    m = JointGraphAER(node_in, edge_in, FINAL_CFG, num_extra_feats=4).to(device)\n",
        "    m.load_state_dict(sd, strict=True)\n",
        "    m.eval()\n",
        "    models.append(m)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load external dataset + build PyG list\n",
        "# -----------------------------------------------------------\n",
        "df_ext = pd.read_csv(EXT_PATH)\n",
        "\n",
        "df_ext = df_ext.rename(columns={\n",
        "    \"SMILES\": \"SMILES(modred)\",\n",
        "    \"Block_A\": \"Block A (x)\",\n",
        "    \"Block_B\": \"Block B (1-x)\",\n",
        "    \"A/B_ratio\": \"Block A/B ratio\",\n",
        "    \"polymer_type\": \"Polymer type\",\n",
        "    \"conductivity\": \"Membrane Anion Conductivity [S/cm]\"\n",
        "})\n",
        "\n",
        "df_ext[\"Block A (x)\"] /= 100.0\n",
        "df_ext[\"Block B (1-x)\"] /= 100.0\n",
        "\n",
        "data_list, y_true, keep = [], [], []\n",
        "\n",
        "for i, row in df_ext.iterrows():\n",
        "    d = smiles_to_pyg(str(row[\"SMILES(modred)\"]), FINAL_CFG)\n",
        "    if d is None:\n",
        "        continue\n",
        "\n",
        "    d.num_feats = torch.tensor([\n",
        "        float(row[\"Block A (x)\"]),\n",
        "        float(row[\"Block B (1-x)\"]),\n",
        "        float(row[\"Block A/B ratio\"]),\n",
        "        float(row[\"Polymer type\"])\n",
        "    ], dtype=torch.float32)\n",
        "\n",
        "    data_list.append(d)\n",
        "    y_true.append(float(row[\"Membrane Anion Conductivity [S/cm]\"]))\n",
        "    keep.append(i)\n",
        "\n",
        "loader = DataLoader(data_list, batch_size=32, shuffle=False)\n",
        "y_true = np.asarray(y_true, dtype=np.float32)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Inference + metrics (MATCHES eval_ensemble semantics)\n",
        "# -----------------------------------------------------------\n",
        "pred_chunks = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        preds = []\n",
        "        for m in models:\n",
        "            y_hat, _, _, _ = m(batch)\n",
        "            preds.append(y_hat.view(-1).cpu().numpy())\n",
        "        pred_chunks.append(np.mean(preds, axis=0))\n",
        "\n",
        "y_pred_t = np.concatenate(pred_chunks)\n",
        "y_pred = pt.inverse_transform(y_pred_t.reshape(-1, 1)).ravel()\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = float(np.sqrt(mse))\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== External Dataset Metrics ===\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MSE:  {mse:.6f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "\n",
        "df_out = df_ext.loc[keep].copy()\n",
        "df_out[\"Predicted Conductivity [S/cm]\"] = y_pred\n",
        "\n",
        "print(\"\\nPreview:\")\n",
        "print(df_out[[\n",
        "    \"SMILES(modred)\",\n",
        "    \"Membrane Anion Conductivity [S/cm]\",\n",
        "    \"Predicted Conductivity [S/cm]\"\n",
        "]].head())\n",
        "\n",
        "df_out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JY_LlHcFhCPA",
        "outputId": "220db8a9-9147-40fb-8b12-f5336a513191"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== External Dataset Metrics ===\n",
            "MAE:  0.0409\n",
            "RMSE: 0.0456\n",
            "MSE:  0.002078\n",
            "R²:   -2.7248\n",
            "\n",
            "Preview:\n",
            "                                      SMILES(modred)  \\\n",
            "0                         C(C)C[N+](C)(C)CCCCCCNC(C)   \n",
            "1                      C(C)C[N+]1(CCCCCCNC(C))CCCCC1   \n",
            "2  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...   \n",
            "3  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...   \n",
            "4  C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...   \n",
            "\n",
            "   Membrane Anion Conductivity [S/cm]  Predicted Conductivity [S/cm]  \n",
            "0                             0.08217                       0.136676  \n",
            "1                             0.04349                       0.109786  \n",
            "2                             0.01290                       0.061649  \n",
            "3                             0.01860                       0.063522  \n",
            "4                             0.02950                       0.067275  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       SMILES(modred)  Block A (x)  \\\n",
              "0                          C(C)C[N+](C)(C)CCCCCCNC(C)         0.87   \n",
              "1                       C(C)C[N+]1(CCCCCCNC(C))CCCCC1         0.87   \n",
              "2   C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.64   \n",
              "3   C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.67   \n",
              "4   C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.73   \n",
              "5   C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...         0.75   \n",
              "6   CC(C)(C)c1ccc(C(C))cc1 CC(CCCC(CC(C)CCC)c2ccc(...         0.30   \n",
              "7                    CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.59   \n",
              "8                    CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.68   \n",
              "9                    CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.80   \n",
              "10                   CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)         0.96   \n",
              "11                CC(CCCC)(CCC)C[N+](C)(C)CC(CCCC)CCC         0.29   \n",
              "12                CC(CCCC)(CCC)C[N+](C)(C)CC(CCCC)CCC         0.33   \n",
              "13                 CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.22   \n",
              "14                 CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.29   \n",
              "15                 CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.36   \n",
              "16  CCC[N+](C)(C)CCCCCCCc1ccccc1c3ccc(c2c(C)c(O)c(...         0.50   \n",
              "17                    C[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.33   \n",
              "18                    C[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.42   \n",
              "19                    C[n+]1ccn(C(C))c1c1ccc(C(C))cc1         0.45   \n",
              "\n",
              "    Block B (1-x)  Block A/B ratio  Polymer type  \\\n",
              "0            0.13         6.692308           1.0   \n",
              "1            0.13         6.692308           1.0   \n",
              "2            0.36         1.777778           1.0   \n",
              "3            0.33         2.030303           1.0   \n",
              "4            0.27         2.703704           1.0   \n",
              "5            0.25         3.000000           1.0   \n",
              "6            0.70         0.428571           1.0   \n",
              "7            0.41         1.439024           1.0   \n",
              "8            0.32         2.125000           1.0   \n",
              "9            0.20         4.000000           1.0   \n",
              "10           0.04        24.000000           1.0   \n",
              "11           0.71         0.408451           1.0   \n",
              "12           0.67         0.492537           1.0   \n",
              "13           0.78         0.282051           1.0   \n",
              "14           0.71         0.408451           1.0   \n",
              "15           0.64         0.562500           1.0   \n",
              "16           0.50         1.000000           1.0   \n",
              "17           0.66         0.500000           1.0   \n",
              "18           0.58         0.724138           1.0   \n",
              "19           0.54         0.833333           1.0   \n",
              "\n",
              "    Membrane Anion Conductivity [S/cm]  Predicted Conductivity [S/cm]  \n",
              "0                             0.082170                       0.136676  \n",
              "1                             0.043490                       0.109786  \n",
              "2                             0.012900                       0.061649  \n",
              "3                             0.018600                       0.063522  \n",
              "4                             0.029500                       0.067275  \n",
              "5                             0.041460                       0.068497  \n",
              "6                             0.098000                       0.077910  \n",
              "7                             0.059933                       0.104692  \n",
              "8                             0.056560                       0.106256  \n",
              "9                             0.040420                       0.107831  \n",
              "10                            0.012800                       0.099220  \n",
              "11                            0.049500                       0.086905  \n",
              "12                            0.056500                       0.088872  \n",
              "13                            0.015850                       0.040257  \n",
              "14                            0.018750                       0.043498  \n",
              "15                            0.032917                       0.046659  \n",
              "16                            0.042000                       0.116948  \n",
              "17                            0.010928                       0.033597  \n",
              "18                            0.014583                       0.035881  \n",
              "19                            0.019033                       0.036824  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25cd8ce6-c97c-43a7-a3e2-1f4115d64f27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES(modred)</th>\n",
              "      <th>Block A (x)</th>\n",
              "      <th>Block B (1-x)</th>\n",
              "      <th>Block A/B ratio</th>\n",
              "      <th>Polymer type</th>\n",
              "      <th>Membrane Anion Conductivity [S/cm]</th>\n",
              "      <th>Predicted Conductivity [S/cm]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C(C)C[N+](C)(C)CCCCCCNC(C)</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>6.692308</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.082170</td>\n",
              "      <td>0.136676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C(C)C[N+]1(CCCCCCNC(C))CCCCC1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>6.692308</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.043490</td>\n",
              "      <td>0.109786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.777778</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>0.061649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.030303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.063522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.703704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.067275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>C1=CC(C[N+](C)(C)C)=C(C(C)=C1)OC1=CC(C)=C(C(C)...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.041460</td>\n",
              "      <td>0.068497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CC(C)(C)c1ccc(C(C))cc1 CC(CCCC(CC(C)CCC)c2ccc(...</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.098000</td>\n",
              "      <td>0.077910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.439024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.059933</td>\n",
              "      <td>0.104692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.32</td>\n",
              "      <td>2.125000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056560</td>\n",
              "      <td>0.106256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.20</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.040420</td>\n",
              "      <td>0.107831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CC(C)C(C)C[N+](C)(C)CCCCCCCCC(C)</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.04</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>0.099220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CC(CCCC)(CCC)C[N+](C)(C)CC(CCCC)CCC</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.049500</td>\n",
              "      <td>0.086905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CC(CCCC)(CCC)C[N+](C)(C)CC(CCCC)CCC</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056500</td>\n",
              "      <td>0.088872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.015850</td>\n",
              "      <td>0.040257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018750</td>\n",
              "      <td>0.043498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CCCC[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032917</td>\n",
              "      <td>0.046659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CCC[N+](C)(C)CCCCCCCc1ccccc1c3ccc(c2c(C)c(O)c(...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.042000</td>\n",
              "      <td>0.116948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>C[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010928</td>\n",
              "      <td>0.033597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>C[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014583</td>\n",
              "      <td>0.035881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>C[n+]1ccn(C(C))c1c1ccc(C(C))cc1</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019033</td>\n",
              "      <td>0.036824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25cd8ce6-c97c-43a7-a3e2-1f4115d64f27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25cd8ce6-c97c-43a7-a3e2-1f4115d64f27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25cd8ce6-c97c-43a7-a3e2-1f4115d64f27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bb75dd34-3405-47dc-8f18-cac74cb328c5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb75dd34-3405-47dc-8f18-cac74cb328c5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bb75dd34-3405-47dc-8f18-cac74cb328c5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6a1d0667-9606-4786-ab70-b5f1f7a2168b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_out')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6a1d0667-9606-4786-ab70-b5f1f7a2168b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_out');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_out",
              "summary": "{\n  \"name\": \"df_out\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"SMILES(modred)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"CCC[N+](C)(C)CCCCCCCc1ccccc1c3ccc(c2c(C)c(O)c(C)cc2)cc3CCCCCCC[N+](C)(C)CCC Cc1cc()cc(C)c1O\",\n          \"C(C)C[N+]1(CCCCCCNC(C))CCCCC1\",\n          \"CC(CCCC)(CCC)C[N+](C)(C)CC(CCCC)CCC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Block A (x)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23142294386548717,\n        \"min\": 0.22,\n        \"max\": 0.96,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.87,\n          0.64,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Block B (1-x)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23070315855753049,\n        \"min\": 0.04,\n        \"max\": 0.78,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.13,\n          0.36,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Block A/B ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.30528277903114,\n        \"min\": 0.282051282051282,\n        \"max\": 24.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          6.6923076923076925,\n          1.7777777777777777,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polymer type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Membrane Anion Conductivity [S/cm]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024231117766398327,\n        \"min\": 0.0109283333333333,\n        \"max\": 0.098,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0821699999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Conductivity [S/cm]\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.13667607307434082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# Strategy #3: Regressor-only fine-tuning (EXTERNAL DATA)\n",
        "# ===========================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from rdkit import Chem, RDLogger\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool, BatchNorm\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Paths\n",
        "# -----------------------------------------------------------\n",
        "ARTIFACT_PATH = \"option4b_graph_joint_ae_regressor_ensemble.pt\"\n",
        "PT_PATH = \"target_transform.joblib\"\n",
        "EXT_PATH = \"/content/drive/MyDrive/Pegah_works/validation_datasset/External_VALID_POLYMER_MEAN_ONLY.csv\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load trained artifacts\n",
        "# -----------------------------------------------------------\n",
        "ckpt = torch.load(ARTIFACT_PATH, map_location=device, weights_only=False)\n",
        "CFG = ckpt[\"config\"]\n",
        "pt = joblib.load(PT_PATH)\n",
        "\n",
        "state = ckpt[\"joint_states\"][0]\n",
        "\n",
        "def unwrap_swa_state_dict(sd):\n",
        "    out = {}\n",
        "    for k, v in sd.items():\n",
        "        if k == \"n_averaged\":\n",
        "            continue\n",
        "        if k.startswith(\"module.\"):\n",
        "            k = k[len(\"module.\"):]\n",
        "        out[k] = v\n",
        "    return out\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Feature construction (IDENTICAL to training)\n",
        "# -----------------------------------------------------------\n",
        "def atom_features(atom, cfg):\n",
        "    nums, hybs, charges, max_deg = cfg[\"atom_nums\"], cfg[\"hybs\"], cfg[\"charges\"], cfg[\"max_degree\"]\n",
        "    f_num = [atom.GetAtomicNum() == z for z in nums] + [atom.GetAtomicNum() not in nums]\n",
        "    d = atom.GetTotalDegree()\n",
        "    f_deg = [d == k for k in range(max_deg + 1)] + [d > max_deg]\n",
        "    ch = atom.GetFormalCharge()\n",
        "    f_ch = [ch == c for c in charges] + [ch not in charges]\n",
        "    hyb = atom.GetHybridization()\n",
        "    f_hy = [hyb == h for h in hybs] + [hyb not in hybs]\n",
        "    misc = [atom.GetIsAromatic(), atom.IsInRing()]\n",
        "    cont = [atom.GetTotalNumHs(includeNeighbors=True), atom.GetImplicitValence()]\n",
        "    return torch.tensor(f_num + f_deg + f_ch + f_hy + misc + cont, dtype=torch.float32)\n",
        "\n",
        "def bond_features(bond, cfg):\n",
        "    btypes = cfg[\"bond_types\"]\n",
        "    f = [bond.GetBondType() == t for t in btypes] + [bond.GetBondType() not in btypes]\n",
        "    misc = [bond.GetIsConjugated(), bond.IsInRing()]\n",
        "    return torch.tensor(f + misc, dtype=torch.float32)\n",
        "\n",
        "def smiles_to_pyg(smiles, cfg):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    Chem.Kekulize(mol, clearAromaticFlags=False)\n",
        "\n",
        "    x = torch.stack([atom_features(a, cfg) for a in mol.GetAtoms()])\n",
        "\n",
        "    ei, ea = [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        bf = bond_features(b, cfg)\n",
        "        ei += [[i, j], [j, i]]\n",
        "        ea += [bf, bf]\n",
        "\n",
        "    edge_index = torch.tensor(ei, dtype=torch.long).t() if ei else torch.empty((2, 0), dtype=torch.long)\n",
        "    edge_attr  = torch.stack(ea) if ea else torch.empty((0, len(cfg[\"bond_types\"]) + 3))\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Model (MATCHES TRAINING ARCHITECTURE)\n",
        "# -----------------------------------------------------------\n",
        "class JointGraphAER(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        node_dim = len(atom_features(Chem.MolFromSmiles(\"C\").GetAtomWithIdx(0), cfg))\n",
        "        edge_dim = len(bond_features(Chem.MolFromSmiles(\"CC\").GetBondWithIdx(0), cfg))\n",
        "\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        last = node_dim\n",
        "\n",
        "        for _ in range(cfg[\"enc_layers\"]):\n",
        "            self.encoder.append(\n",
        "                GINEConv(\n",
        "                    nn.Sequential(\n",
        "                        nn.Linear(last, cfg[\"enc_hidden\"]),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(cfg[\"enc_hidden\"], cfg[\"enc_hidden\"])\n",
        "                    ),\n",
        "                    edge_dim=edge_dim\n",
        "                )\n",
        "            )\n",
        "            self.bns.append(BatchNorm(cfg[\"enc_hidden\"]))\n",
        "            last = cfg[\"enc_hidden\"]\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(cfg[\"enc_hidden\"] + 4, cfg[\"growth\"]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg[\"growth\"], 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        for conv, bn in zip(self.encoder, self.bns):\n",
        "            x = bn(F.relu(conv(x, data.edge_index, data.edge_attr)))\n",
        "\n",
        "        z = global_mean_pool(x, data.batch)\n",
        "\n",
        "        nf = data.num_feats.to(z.device)\n",
        "        if nf.dim() == 1:\n",
        "            nf = nf.view(z.size(0), -1)\n",
        "\n",
        "        if nf.size(1) > 4:\n",
        "            nf = nf[:, :4]\n",
        "        elif nf.size(1) < 4:\n",
        "            pad = torch.zeros(z.size(0), 4 - nf.size(1), device=z.device)\n",
        "            nf = torch.cat([nf, pad], dim=1)\n",
        "\n",
        "        z = torch.cat([z, nf], dim=1)\n",
        "        return self.regressor(z)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load model + freeze encoder\n",
        "# -----------------------------------------------------------\n",
        "model = JointGraphAER(CFG).to(device)\n",
        "model.load_state_dict(unwrap_swa_state_dict(state), strict=False)\n",
        "\n",
        "for p in model.encoder.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.bns.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.regressor.parameters(), lr=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load external dataset\n",
        "# -----------------------------------------------------------\n",
        "df = pd.read_csv(EXT_PATH)\n",
        "\n",
        "data_list = []\n",
        "y_true = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    d = smiles_to_pyg(row[\"SMILES(modred)\"], CFG)\n",
        "    if d is None:\n",
        "        continue\n",
        "\n",
        "    d.num_feats = torch.tensor([\n",
        "        row[\"Block A (x)\"],\n",
        "        row[\"Block B (1-x)\"],\n",
        "        row[\"Block A/B ratio\"],\n",
        "        row[\"Polymer type\"]\n",
        "    ], dtype=torch.float32)\n",
        "\n",
        "    data_list.append(d)\n",
        "    y_true.append(row[\"Membrane Anion Conductivity [S/cm]\"])\n",
        "\n",
        "y_true = np.asarray(y_true, dtype=np.float32)\n",
        "y_t = torch.tensor(pt.transform(y_true.reshape(-1, 1)), dtype=torch.float32)\n",
        "\n",
        "loader = DataLoader(data_list, batch_size=8, shuffle=True)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Fine-tuning\n",
        "# -----------------------------------------------------------\n",
        "model.train()\n",
        "for epoch in range(80):\n",
        "    for batch, yb in zip(loader, y_t.split(8)):\n",
        "        batch = batch.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        pred = model(batch)\n",
        "        loss = loss_fn(pred, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Evaluation\n",
        "# -----------------------------------------------------------\n",
        "model.eval()\n",
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        preds.append(model(batch.to(device)).cpu().numpy())\n",
        "\n",
        "y_pred = pt.inverse_transform(np.vstack(preds)).ravel()\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "rho, pval = spearmanr(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== Strategy #3 Results ===\")\n",
        "print(\"MAE        :\", mean_absolute_error(y_true, y_pred))\n",
        "print(\"RMSE       :\", rmse)\n",
        "#print(\"Spearman ρ :\", rho)\n",
        "#print(\"p-value    :\", pval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx-hra5rsULy",
        "outputId": "d7c70ff6-bbb3-43da-c233-e412f8c73619"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Strategy #3 Results ===\n",
            "MAE        : 0.01925985887646675\n",
            "RMSE       : 0.024675809126954894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# Common settings\n",
        "# -------------------------------\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 12,\n",
        "    \"axes.linewidth\": 1.2\n",
        "})\n",
        "\n",
        "# -------------------------------\n",
        "# Figure: Absolute error vs target\n",
        "# -------------------------------\n",
        "abs_err = np.abs(y_true - y_pred)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "\n",
        "plt.scatter(\n",
        "    y_true,\n",
        "    abs_err,\n",
        "    s=60,\n",
        "    edgecolor=\"black\",\n",
        "    linewidth=0.8,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Experimental Conductivity (S/cm)\")\n",
        "plt.ylabel(\"Absolute Error (S/cm)\")\n",
        "plt.title(\"Absolute Prediction Error\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig_absolute_error_external_strategy3.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved figure: fig_absolute_error_external_strategy3.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "j3e7Jn-tvjgH",
        "outputId": "ffc22b35-96fa-4af8-da3e-c2c1d2395546"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved figure: fig_absolute_error_external_strategy3.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pzGg2nQx-3B7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}